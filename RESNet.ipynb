{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from keras.layers import Input, Lambda, Dense, Flatten\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update these paths according to your directory structure\n",
    "home_directory = os.path.expanduser('~')\n",
    "dataset_directory = os.path.join(home_directory, \"Downloads/archive/new plant diseases dataset(augmented)/New Plant Diseases Dataset(Augmented)\")\n",
    "train_path = os.path.join(dataset_directory, \"train\")\n",
    "valid_path = os.path.join(dataset_directory, \"valid\")\n",
    "\n",
    "from tensorflow.keras.applications.resnet import ResNet50\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.resnet import preprocess_input, decode_predictions\n",
    "from tensorflow.keras.applications.resnet import ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(\n",
    "    preprocessing_function=preprocess_input,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "IMG_SIZE = [256,256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = ResNet50(\n",
    "    include_top=False,\n",
    "    weights=\"imagenet\",\n",
    "    input_shape=IMG_SIZE+[3],\n",
    "    classifier_activation=\"softmax\",\n",
    ")\n",
    "resnet.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in resnet.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = glob(train_path + \"/*\")\n",
    "print(len(folders))\n",
    "classes = len(folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Flatten()(resnet.output)\n",
    "prediction = Dense(len(folders), activation='softmax')(x)\n",
    "model = Model(inputs=resnet.input, outputs=prediction)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "\n",
    "\n",
    "adam = optimizers.Adam()\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=adam,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from datetime import datetime\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "batch_size = 16;\n",
    "\n",
    "\n",
    "train_set = train_datagen.flow_from_directory(train_path,\n",
    "                                                 target_size=(256, 256),\n",
    "                                                 batch_size=batch_size,\n",
    "                                                 class_mode='categorical')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(valid_path,\n",
    "                                                target_size=(256, 256),\n",
    "                                                batch_size=batch_size,\n",
    "                                                class_mode='categorical')\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath=f'model_batch_{batch_size}.h5',\n",
    "                                 verbose=2, save_best_only=True)\n",
    "\n",
    "callbacks = [checkpoint]\n",
    "\n",
    "start = datetime.now()\n",
    "\n",
    "model_history = model.fit_generator(\n",
    "    train_set,\n",
    "    validation_data=test_set,\n",
    "    epochs=60,\n",
    "    steps_per_epoch=5,\n",
    "    validation_steps=32,\n",
    "    callbacks=callbacks, verbose=2)\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(f\"Training with batch size {batch_size} completed in time: {duration}\")\n",
    "\n",
    "# Save training and validation accuracy values to a .txt file\n",
    "with open(f'model_50_history_batch_{batch_size}.txt', 'w') as f:\n",
    "    f.write(f'Training Accuracy: {model_history.history[\"accuracy\"]}\\n')\n",
    "    f.write(f'Validation Accuracy: {model_history.history[\"val_accuracy\"]}\\n')\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(model_history.history['accuracy'])\n",
    "plt.plot(model_history.history['val_accuracy'])\n",
    "plt.title(f'ResNET50 Model accuracy values - Batch Size {batch_size}')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.savefig(f'plot_50_batch_{batch_size}.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from datetime import datetime\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "batch_size = 32;\n",
    "\n",
    "\n",
    "train_set = train_datagen.flow_from_directory(train_path,\n",
    "                                                 target_size=(256, 256),\n",
    "                                                 batch_size=batch_size,\n",
    "                                                 class_mode='categorical')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(valid_path,\n",
    "                                                target_size=(256, 256),\n",
    "                                                batch_size=batch_size,\n",
    "                                                class_mode='categorical')\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath=f'model_batch_{batch_size}.h5',\n",
    "                                 verbose=2, save_best_only=True)\n",
    "\n",
    "callbacks = [checkpoint]\n",
    "\n",
    "start = datetime.now()\n",
    "\n",
    "model_history = model.fit_generator(\n",
    "    train_set,\n",
    "    validation_data=test_set,\n",
    "    epochs=60,\n",
    "    steps_per_epoch=5,\n",
    "    validation_steps=32,\n",
    "    callbacks=callbacks, verbose=2)\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(f\"Training with batch size {batch_size} completed in time: {duration}\")\n",
    "\n",
    "# Save training and validation accuracy values to a .txt file\n",
    "with open(f'model_50_history_batch_{batch_size}.txt', 'w') as f:\n",
    "    f.write(f'Training Accuracy: {model_history.history[\"accuracy\"]}\\n')\n",
    "    f.write(f'Validation Accuracy: {model_history.history[\"val_accuracy\"]}\\n')\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(model_history.history['accuracy'])\n",
    "plt.plot(model_history.history['val_accuracy'])\n",
    "plt.title(f'ResNET50 Model accuracy values - Batch Size {batch_size}')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.savefig(f'plot_50_batch_{batch_size}.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "batch_size = 64;\n",
    "\n",
    "\n",
    "train_set = train_datagen.flow_from_directory(train_path,\n",
    "                                                 target_size=(256, 256),\n",
    "                                                 batch_size=batch_size,\n",
    "                                                 class_mode='categorical')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(valid_path,\n",
    "                                                target_size=(256, 256),\n",
    "                                                batch_size=batch_size,\n",
    "                                                class_mode='categorical')\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath=f'model_batch_{batch_size}.h5',\n",
    "                                 verbose=2, save_best_only=True)\n",
    "\n",
    "callbacks = [checkpoint]\n",
    "\n",
    "start = datetime.now()\n",
    "\n",
    "model_history = model.fit_generator(\n",
    "    train_set,\n",
    "    validation_data=test_set,\n",
    "    epochs=60,\n",
    "    steps_per_epoch=5,\n",
    "    validation_steps=32,\n",
    "    callbacks=callbacks, verbose=2)\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(f\"Training with batch size {batch_size} completed in time: {duration}\")\n",
    "\n",
    "# Save training and validation accuracy values to a .txt file\n",
    "with open(f'model_101_history_batch_{batch_size}.txt', 'w') as f:\n",
    "    f.write(f'Training Accuracy: {model_history.history[\"accuracy\"]}\\n')\n",
    "    f.write(f'Validation Accuracy: {model_history.history[\"val_accuracy\"]}\\n')\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(model_history.history['accuracy'])\n",
    "plt.plot(model_history.history['val_accuracy'])\n",
    "plt.title(f'ResNET101 Model accuracy values - Batch Size {batch_size}')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.savefig(f'plot_101_batch_{batch_size}.png')\n",
    "plt.show()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "from datetime import datetime\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "batch_size = 128;\n",
    "\n",
    "\n",
    "train_set = train_datagen.flow_from_directory(train_path,\n",
    "                                                 target_size=(256, 256),\n",
    "                                                 batch_size=batch_size,\n",
    "                                                 class_mode='categorical')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(valid_path,\n",
    "                                                target_size=(256, 256),\n",
    "                                                batch_size=batch_size,\n",
    "                                                class_mode='categorical')\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath=f'model_batch_{batch_size}.h5',\n",
    "                                 verbose=2, save_best_only=True)\n",
    "\n",
    "callbacks = [checkpoint]\n",
    "\n",
    "start = datetime.now()\n",
    "\n",
    "model_history = model.fit_generator(\n",
    "    train_set,\n",
    "    validation_data=test_set,\n",
    "    epochs=60,\n",
    "    steps_per_epoch=5,\n",
    "    validation_steps=32,\n",
    "    callbacks=callbacks, verbose=2)\n",
    "\n",
    "duration = datetime.now() - start\n",
    "print(f\"Training with batch size {batch_size} completed in time: {duration}\")\n",
    "\n",
    "# Save training and validation accuracy values to a .txt file\n",
    "with open(f'model_101_history_batch_{batch_size}.txt', 'w') as f:\n",
    "    f.write(f'Training Accuracy: {model_history.history[\"accuracy\"]}\\n')\n",
    "    f.write(f'Validation Accuracy: {model_history.history[\"val_accuracy\"]}\\n')\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(model_history.history['accuracy'])\n",
    "plt.plot(model_history.history['val_accuracy'])\n",
    "plt.title(f'ResNET101 Model accuracy values - Batch Size {batch_size}')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.savefig(f'plot_101_batch_{batch_size}.png')\n",
    "plt.show()\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
